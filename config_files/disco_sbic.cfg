################################################################################
# Configuration for training an DisCo on label distribution design matrices
################################################################################
out_dir = ./experimental_data/sbic_intent/

# numpy arrays/design matrices for fitting the DisCo model
xi_fname = ./experimental_data/sbic_intent/Xi_train.npy
yi_fname = ./experimental_data/sbic_intent/Yi_train.npy
ya_fname = ./experimental_data/sbic_intent/Ya_train.npy
y_fname = ./experimental_data/sbic_intent/Y_train.npy
i_fname = ./experimental_data/sbic_intent/I_train.npy
a_fname = ./experimental_data/sbic_intent/A_train.npy

# optional numpy arrays to validate DisCo generalization performance during training
dev_xi_fname = ./experimental_data/sbic_intent/Xi_dev.npy
dev_yi_fname = ./experimental_data/sbic_intent/Yi_dev.npy
dev_ya_fname = ./experimental_data/sbic_intent/Ya_dev.npy
dev_y_fname = ./experimental_data/sbic_intent/Y_dev.npy
dev_i_fname = ./experimental_data/sbic_intent/I_dev.npy
dev_a_fname = ./experimental_data/sbic_intent/A_dev.npy

# training meta-parameters
n_epoch = 200 #35 #100 #100 #200
batch_size = 200 #200 #100 #128
save_every = 10
eval_every = 10

################################################################################
# set up disco learning model (offline)
################################################################################
act_fx = softsign
weight_init_scheme = gaussian
gamma_i = 0.0
gamma_a = 0.0
# ^^ NOTE: if you use relu/relu6 act_fx, use he_uniform/he_normal init scheme to boost performance
lat_i_dim = 128 #100
lat_a_dim = 64 #50
lat_fusion_type = concat #sum
lat_dim = 128 # 100 # try powers of 2 to boost GPU performance
opt_type = adam
learning_rate = 0.002
update_radius = -2.0 # if > 0, hard clips the gradients to not exceed values of [-update_radius, update_radius]
drop_p = 0.5
